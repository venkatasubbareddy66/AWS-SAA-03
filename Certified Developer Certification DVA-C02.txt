

IMP NOTE : ALL the Topics have covered in the Solution architect Associate , here I have prepared the Most advanced topics for Associate Developer which was not covered in the solution architect associate



=========================================================== CloudFront =========================================


-------------------- CloudFront Caching 

• The cache lives at each CloudFront Edge Location

• CloudFront identifies each object in the cache using the Cache Key 

• You want to maximize the Cache Hit ratio to minimize requests to the origin

• You can invalidate part of the cache using the CreateInvalidation API


-------------------- What is CloudFront Cache Key?

• A unique identifier for every object in the cache

• By default, consists of hostname + resource portion of the URL

• If you have an application that serves up content that varies based on user, device, language, location...

• You can add other elements (HTTP headers, cookies, query strings) to the Cache Key using "CloudFront Cache Policies"


-------------------- CloudFront Policies – Cache Policy

• Cache based on:

    • HTTP Headers: None – Whitelist

    • Cookies: None – Whitelist – Include All-Except – All

    • Query Strings: None – Whitelist – Include All-Except – All


• Control the TTL (0 seconds to 1 year), can be set by the origin using the Cache-Control header, Expires header...

• Create your own policy or use Predefined Managed Policies

IMP : • All HTTP headers, cookies, and query strings that you include in the Cache Key are automatically included and forward to ur  origin requests



------------------ 1 CloudFront Caching – Cache Policy HTTP Headers

- let's say we have an example request in french language


GET /blogs/myblog.html HTTP/1.1
Host: mywebsite.com
User-Agent: Mozilla/5.0 (Mac OS X 10_15_2....) 
Date: Tue, 28 Jan 2021 17:01:57 GMT 
Authorization: SAPISIDHASH fdd00ecee39fe.... Keep-Alive: 300
Language: fr-fr


-- so if we define none : 

• None:
   
    • Don’t include any headers in the Cache Key (except default)
    • Headers are not forwarded (except default)
    • Best caching performance

• Whitelist: 

    • only specified headers included in the Cache Key
      
       -     if u want to whitelist specific Headers and that may mean necessary because while you want to have the language as a Cache Key, then you specify which headers you want to include in the Cache Key,

    • Specified headers are also forwarded to Origin

       - so that the origin can actually respond to the request and give you the blog in the correct language.




---------------------------- 2 CloudFront Cache – Cache Policy Query Strings


- for example we have a request like 

 GET /image/cat.jpg?border=red&size=large HTTP/1.1


-- So query strings are what happens in the URL after a question mark. 

-- So for example, border equals red and size equals large. So here, we want a cat image. But apparently, it's going to be customized a little bit by the origin.

-- if you have 

• None : 

    • Don’t include any query strings in the Cache Key

    • Query strings are not forwarded

• Whitelist

    • Only specified query strings included in the Cache Key

    • Only specified query strings are forwarded


• Include All-Except : you specify which ones you don't want but the rest passes

    • Include all query strings in the Cache Key except the specified list

    • All query strings are forwarded except the specified list


• All

    • Include all query strings in the Cache Key

    • All query strings are forwarded

    • Worst caching performance




------------------------------ CloudFront Policies – Origin Request Policy 


• Specify values that you want to include in origin requests without including them in the Cache Key (no duplicated cached content)

• You can include extra :
      
      • HTTP headers: None – Whitelist – All viewer headers options
      • Cookies: None – Whitelist – All
      • Query Strings: None – Whitelist – All

    - but they will be forwarded to the origin but they're not going to be used in the Cache Key.


• Ability to add CloudFront HTTP headers and Custom Headers to an origin request that were not included in the viewer request (eg :  if you wanted to pass an API key or a secret header.)

• Create your own policy or use Predefined Managed Policies



----------------------------- Cache Policy vs. Origin Request Policy


GET /blogs/myblog.html HTTP/1.1
Host: mywebsite.com
User-Agent: Mozilla/5.0 (Mac OS X 10_15_2....) 
Date: Tue, 28 Jan 2021 17:01:57 GMT 
Authorization: SAPISIDHASH fdd00ecee39fe.... Keep-Alive: 300
Language: fr-fr


--  so the request will come with some query strings, some cookies, some headers, and then we will cache based on the cache policy.

-- For example, we want to cache here on the host name, the resource, and a header called authorization.



-- But then, your origin may need more than these three things to actually work and to actually serve properly the request.

-- So you may want to add the user agents,the session ID and the ref query string as part of your request to the origin.

-- So in this case, the request to the origin is going to be enhanced but then the caching will not happen based on what we forwarded to the origin request policy.

-- It's only going to be based on the cache policy.







Client ------------------------------(request)----------------------------> C.F --------------------------(forward)--------------------------------> Origin (EC2 instance)
                                                                             |

                   Cache Policy                                           EDGE Location                   Origin Request Policy (whitelist)

                Cache Key (cache based on)                                  |                                  Type                        Value
                                                                            |                               HTTP Headers         User-Agent, Authorization
                 - mywebsite.com 
                 - /content/stories/example-story.html                     CACHE                            Cookies               session_id
                 - Header: Authorization                                                                    Query Strings          ref


    


----------------------------------- CloudFront – Cache Invalidations


• In case you update the back-end origin, CloudFront doesn’t know about it and will only get the refreshed content after the TTL has expired

• However, you can force an entire or partial cache refresh (thus bypassing the TTL) by performing a CloudFront Invalidation

• You can invalidate all files (*) or a special path (/images/*)


------------------------------------ CloudFront – Cache Behaviors


• Configure different settings for a given URL path pattern

• Example: one specific cache behavior to images/*.jpg files on your origin web server

• Route to different kind of origins/origin groups based on the content type or path pattern
  
      • /images/*
      • /api/*  --  EG : Load balancer 
      • /* (default cache behavior) EG : S3 


• When adding additional Cache Behaviors, the Default Cache Behavior is always the last to be processed and is always /*



------ use case for cache behavior  EG : CloudFront – Cache Behaviors – Sign In Page


                                                                

                                                                        cache behaviours                                                 origins 
           Signed Cookies
       <------------------------->                                    
Users                                           <--------------------------->  /* (default)      -------------------->                      S3
                                          CF Distribution                         
                                                <--------------------------->  /login             ------------------->                EC2 instance (generated signed cookies)
       <------------------------->                                                                <--------------------              
            authenticate                                                                    Signed Cookies              



-- So the way we do it is that we define a cache behavior ,for /login and so the users who hit the /login page will be redirected to our EC2 instance.

-- And the role of our EC2 instance is to generate CloudFront signed cookies.

-- So these signed cookies are sent back to the user and the user will then use the signed cookies to be able to access our default cache behavior, which is any other URL, then /login and then access our S3 bucket files.

-- if the users are trying to access the default cache behavior without doing a login first, what we can do is that we can set up the cache behavior to only accept the request if signed cookies are present.

-- Therefore, we can redirect to the /login page and we're good to go.



---------------------------------------- CloudFront – Maximize cache hits by separating static and dynamic distributions



Static requests --------------> CDN Layer CloudFront (No headers / session caching rules Required for maximizing cache hits) ------(Static content)-----------> S3

Dynamic         --------------> CDN Layer CloudFront (Cache based on correct headers and cookie)------------------(Dynamic Content (REST, HTTP server))----------------> ALB + EC2 





--------------------------------------- CloudFront Signed URL / Signed Cookies


• You want to distribute paid shared content to premium users over the world

• We can use CloudFront Signed URL / Cookie. We attach a policy with:

      • Includes URL expiration
      • Includes IP ranges to access the data from
      • Trusted signers (which AWS accounts can create signed URLs)

• How long should the URL be valid for?

     • Shared content (movie, music): make it short (a few minutes)
     • Private content (private to the user): you can make it last for years


• Signed URL = access to individual files (one signed URL per file)

• Signed Cookies = access to multiple files (one signed cookie for many files)



------------------------------------------ CloudFront Signed URL vs S3 Pre-Signed URL


          • CloudFront Signed URL:                                                                                                • S3 Pre-Signed URL:


• Allow access to a path, no matter the origin  (not only s3 , but HTTP, backend ....)                           • Issue a request as the person who pre-signed the URL

• Account wide key-pair, only the root can manage it                                                             • Uses the IAM key of the signing IAM principal

• Can filter by IP, path, date, expiration                                                                       • Limited lifetime

• Can leverage caching features



------------------------------------------ CloudFront Signed URL Process

• Two types of signers:

    1 • Either a trusted key group (recommended)
        
        • Can leverage APIs to create and rotate keys (and IAM for API security)


    2 • An AWS Account that contains a CloudFront Key Pair

        • Need to manage keys using the root account and the AWS console
        • Not recommended because you shouldn’t use the root account for this



• In your CloudFront distribution, create one or more trusted key groups

• You generate your own public / private key
       
       • The private key is used by your applications (e.g. EC2) to sign URLs
       • The public key (uploaded) is used by CloudFront to verify URLs




---------------------------------------------------------------- LAB Demo 

------------ Type 1 


-- open S3 and create private Bucket 

-- as u create private bucket , no one can access ur url through the S3 

-- Only access through by Cloud-Front directly coz, it is privtae bucket and we did not enable Static hosting also 

-- go to CF in console 

-- create ditrubtion on CF 

-- Origina Domain = load balancer / S3 -- these are the places wher u can host ur applications 

-- OAC --> Create control settings --> do not change any n create 

-- it is created access from S3 

-- Compress objects automatically : CloudFront can automatically compress certain files that it receives from the origin before delivering them to the viewer. CloudFront compresses files only when the viewer supports it, as specified in the Accept-Encoding header in the viewer request.


-- Default root object - optional = index.html  -----> must and should u have to give this , otherwise u won’t get o/p 


----- once u create distrubtion , the S3 bucket policy wil gwt generated copy that policy and paste in bucket policy 

-- now ur appn is getting deployed all over the world 

-- through the CF url customers will able to connect ur webiste through the edge locations 

-- once u change the content of ur website and do uploud again n if u do refresh u won't get new content 

-- u have too do "invalidate the Cache" 

-- go to CF and create invalidation for /index.html or /* , do upload again the file to s3 ,it will get latest file from the S3 and give latest content to customers 

-- By default, CloudFront caches files in edge locations for 24 hours. 


------------ Sign URL System 

--  now i want to make this private , and want to give access to only prime customers 

--  so do create Signed URL'S

-- for this first u have to create public key and do store this key in the Key group 

-- go to google and search for "RSA Key Generator" create 2048 bit key , copy public key and do paste in public key , create public key

-- now create key group and add this public key to this group , u can store upto 5 pulic keys in one group 

-- now go to distribution --> behaviour --> edit --> Restrict viewer access = yes --> save changes 

-- it will get create one URL




TYPE 2 

-- go to security credentials --> create cloudfront key pair --> download both public and private files 

-- now open terminals and enter the command like this 

      aws cloudfront sign --url https://dgw7w0gfg0nkb.cloudfront.net --key-pair-id APKAUK2QS6DOWVAB3OG5 --private-key file://pk-APKAUK2QS6DOWVAB3OG5.pem --date-less-than 2024-03-31


      -- it will generate one url 

      EG :    https://dgw7w0gfg0nkb.cloudfront.net?Expires=1711843200&Signature=Pa7-jzCpDyXKgwS6bqPh75zqiNnCHryUCWDgcQheZLwX7g0wyzLrBSiUmD2KNFtdnx-OKnYLO2zJSiLsORIQO1yDs5RBTCqW6y5BTGqE0-CUdQ5clls4LY4KKdwZWmRs2VyJtMMDNqiwjsID2nTHO8nRUkgWBB0Nx9FShrhsmMoqVYo2JnDmIWnLb8KE4r8vSxbKPmMKByRkqmUmHPSbR6ODct0njHdDbcDJuANZLh3NKXVPvfYNMGre1ipjwfPhz7neEbcZoMq3AYuXce83DzSQd2BN~P8lPKDyDOWy8C3kAHoUKUg~2tneTa9~Ksh2hFHHyOnIthSysoFKmsW5ug__&Key-Pair-Id=APKAUK2QS6DOWVAB3OG5%                                    





--------------------------------------- CloudFront – Multiple Origin

• To route to different kind of origins based on the content type

• Based on path pattern:

      • /images/*
      • /api/* 
      • /*



-------------------------------------- CloudFront – Origin Groups

• To increase high-availability and do failover

• Origin Group: one primary and one secondary origin

• If the primary origin fails, the second one is used


-------------------------------------- CloudFront – Field Level Encryption


• Protect user sensitive information through application stack

• Adds an additional layer of security along with HTTPS

• Sensitive information encrypted at the edge close to user

• Uses asymmetric encryption

• Usage: 

     • Specify set of fields in POST requests that you want to be encrypted (up to 10 fields)
     • Specify the public key to encrypt them


                                      
                                                Encrypt using Public Key

Client -----------(HTTPS)----------------------> EDGE Location ------------(HTTPS)--------------------> C.F -------------(HTTPS)-----------> ALB --------(HTTPS)------------------> WEB Servers

         POST /submit HTTP/1.1 
         Host: www.example.com                                             POST /submit HTTP/1.1                                                                               Decrypt using Private Key
                                                                           Host: www.example.com 



EG : 


LAB : https://325b057e.isolation.zscaler.com/profile/1233fc6e-6618-4022-a03b-96afce7da312/zia-session/?controls_id=5363df57-072a-41ec-8342-91ef13f84e51&region=bom&tenant=462f064b6b51&user=a88c06b13d4badbc3b1628a94e955f23c843810a6a0110d09b7d0213d4fe17aa&original_url=https%3A%2F%2Faws.amazon.com%2Fblogs%2Fsecurity%2Fhow-to-enhance-the-security-of-sensitive-customer-data-by-using-amazon-cloudfront-field-level-encryption%2F&key=sh-1&hmac=dfa6e28bf1bc65f977e7e1b8fb8cd99b505583c03072c2c6e52c6e286b86f799




------------------------------------------ CloudFront – Real Time Logs


• Get real-time requests received by CloudFront sent to Kinesis Data Streams

• Monitor, analyze, and take actions based on content delivery performance

• Allows you to choose:
  
      • Sampling Rate – percentage of requests for which you want to receive

      • Specific fields and specific Cache Behaviors (path patterns)



Real-time Processing  =          Users -----(Requests)--------> C.F -----(LOGS)-------> Kinesis Data Streams ------(records)--------------> Lambda


Near Real-time Processing  =       Users -----(Requests)--------> C.F -----(LOGS)-------> Kinesis Data Streams ------(records)--------------> Kinesis Data Firehose






===================================================== Containers on AWS ========================================

• Docker is a software development platform to deploy apps

• Apps are packaged in containers that can be run on any OS

• Apps run the same, regardless of where they’re run

  • Any machine
  • No compatibility issues
  • Predictable behavior
  • Less work
  • Easier to maintain and deploy
  • Works with any language, any OS, any technology


• Use cases: microservices architecture, lift-and-shift apps from on- premises to the AWS cloud, ...



---------------------------- Where are Docker images stored?

• Docker images are stored in Docker Repositories

• Docker Hub (https://hub.docker.com)

    • Public repository
    • Find base images for many technologies or OS (e.g., Ubuntu, MySQL, ...)


• Amazon ECR (Amazon Elastic Container Registry)

    • Private repository
    • Public repository (Amazon ECR Public Gallery https://gallery.ecr.aws)


-- Jfrog also we can store images





-------------------------- Docker vs.Virtual Machines

• Docker is ”sort of ” a virtualization technology, but not exactly

• Resources are shared with the host => many containers on one server

-- see pics in google for better understanding





-------------------------------- Getting Started with Docker



Dockerfile -------(Build)----------------> Docker Image ------------(Run)------------> Docker Container (Eg :python)
                                            |      |
                                            |      |
                                Push        |      |    Pull
                                            |      |
                                            |      |
              
                                        Docker Repositories

                                        Eg : DockerHub , ECR



-- Dockerfile  : which is defining how your Docker container will look. So we have a base Docker image , and we add some files and then we're going to build it.

-- DockerImage : And this will become a Docker image. And that Docker image, you can store it on a Docker repository , it's called a Push and you push it to either Docker hub which is a public repository, or Amazon is ECR
   
                 - Then you can pull back these images from these repositories and then you would run them.


-- Docker Container : And when you run a Docker image , it becomes a Docker container, which runs your code hat you had built from your Docker build.


--- That is the whole process with Docker.





---------------------------------------------- Docker Containers Management on AWS

• Amazon Elastic Container Service (Amazon ECS)
     
     • Amazon’s own container platform


• Amazon Elastic Kubernetes Service (Amazon EKS)

     • Amazon’s managed Kubernetes (open source)


• AWS Fargate
  
     • Amazon’s own Serverless container platform
     • Works with ECS and with EKS


• Amazon ECR:
  
     • Store container images





--------------------------------------------------- 1 Amazon ECS - EC2 Launch Type


• ECS = Elastic Container Service

• Launch Docker containers on AWS = Launch ECS Tasks on ECS Clusters 
    
        - an ECS Cluster is made of things.And with the EC2 Launch Type, well these things are EC2 instances.

        - group of servers is called "clusters"


• EC2 Launch Type: you must provision & maintain the infrastructure (the EC2 instances)

• Each EC2 Instance must run the ECS Agent to register in the ECS Cluster

• AWS takes care of starting / stopping containers

     - AWS is going to be starting or stopping the containers.
     - That means that whenever we have a new Docker container it's going to be placed accordingly on each EC2 Instance.
     





----------------------------------------------------  2 Amazon ECS – Fargate LaunchType


• Launch Docker containers on AWS

• You do not provision the infrastructure (no EC2 instances to manage)

• It’s all Serverless!, because we don't manage servers (there are servers behind., but we are not managing the servers)

• if we have an ECS Cluster , we just create task definition to define our ECS tasks.

• AWS just runs ECSTasks for you based on the CPU / RAM you need

   - So when we want to run a new Docker container, simple as that, it's going to be run, without us knowing where it's run and without an EC2 Instance to be created in the backend in our accounts for it to work.
   - So it's a little bit magic.


• To scale, just increase the number of tasks. Simple - no more EC2 instances





------------------------------------------------------- Amazon ECS – IAM Roles for ECS


 -- So let's take an example of the EC2 Launch Type in which we have an EC2 Instance running the ECS Agent on Docker.

 -- So in this case, we can create an EC2 Instance Profile which is only valued of course if you use EC2 Launch Type.

 1  EC2 Instance Profile (EC2 Launch Type only):

       • Used by the ECS agent
       • Makes API calls to ECS service
       • Send container logs to CloudWatch Logs
       • Pull Docker image from ECR
       • Reference sensitive data in Secrets Manager or SSM Parameter Store



 2 ECSTask Role:

-- our ECS tasks are going to get ECS Task Roles. And so this is valued for both EC2 Launch Type and Fargate.

-- And so here I have two tasks.And we can create a specific role per task.

           TASK A -----------(EC2 Task A Role)-------> s3 

           TASK B -----------(EC2 Task B Role)-------> DynamoDB

-- Well, why do we have different roles? 

ANS : Because each role allows you to be linked to different ECS services.

1  so, for example, the ECS Task A Role allows you to have your Task A, runs some API calls against Amazon S3

2  so, for example, the ECS Task B Role allows you to have your Task B, runs some API calls against Dynamodb


NOTE : you define the Task Role in the task definition of your ECS service.



• Allows each task to have a specific role

• Use different roles for the different ECS Services you run

• Task Role is defined in the task definition 

     -- task definition : The Task definitions view lists each task definition family you've created.

     -- You can perform the following actions:
        
         - Deploy the task definision as a service or a task.
         - Create a new revision






---------------------------------------------- Amazon ECS – Load Balancer Integrations


1  Application Load Balancer 

    -- supported and works for most use cases

    -- multiple ECS Tasks running. It's all in the ECS Cluster.

    -- And we want to expose these tasks as a HTP or HTTPS endpoint.

    -- Therefore we can run an Application Load Balancer in front of it and then our users will be going to the ALB and in the back end to the ECS tasks directly.

    -- the ALB is supported and will support most use cases, and that's a good choice.


2   Network Load Balancer

    -- recommended only for high throughput / high performance use cases, or to pair it with AWS Private Link


3   Classic Load Balancer supported but not recommended (no advanced features – no Fargate)

    - you cannot link your Elastic Load Balancer to Fargate.






----------------------------------------------------- Amazon ECS – Data Volumes (EFS)


• Mount EFS file systems onto ECS tasks

   - So say you have an ECS cluster and in this case are represented both the EC2 Instance , as well as the Fargate Launch Type for my ECS Cluster.

   - And we want to mount a file system onto the ECS task to share some data. In that case, we use an Amazon EFS file system,


• Works for both EC2 and Fargate launch types

   - because it's a network file system is going to be compatible with both EC2 and the Fargate launch types. And it allows us to mount the file system directly onto our ECS tasks.


• Tasks running in any AZ will share the same data in the EFS file system

• Fargate + EFS = Serverless


• Use cases: persistent multi-AZ shared storage for your containers


IMP NOTE : 

    • Amazon S3 cannot be mounted as a file system ( S3 isn't a file system, it is object storage. )



--------------------------------------------------------- Capacity providers ECS 

-- The capacity provider view provides details about your Fargate and EC2 capacity providers.

-- For Amazon ECS on AWS Fargate, the Capacity Provider is FARGATE and a FARGATE_SPOT and the Type is FargateProvider. When you select AWS Fargate, these providers are added automatically. You cannot update or delete them.

-- For Amazon ECS on Amazon EC2, the Capacity Provider is the Auto Scaling group name and the Type is ASGProvider.

-- For Amazon ECS on Amazon EC2, you can create, update, and delete the capacity provider.

--  When you delete the capacity provide the capacity provider association is removed. You must go the Amazon EC2 console to delete the Auto Scaling group.






---------------------------------------------- LAB for ECS 

-- open ECS , give name for ur cluster

--  do check Fargate and ec2 instances 

-- now it create new ASG automatically for u , go with amazon linux 2 (os) , t2.micro (instance type) 

-- if u want to deploy these in ur vpc then select ur vpc , otherwise go with default vpc 

-- remaining all are default 

-- once the cluster is get created , automatically one ASG get created for u 

-- FARGATE / FARGATE_SPOT / Our ASG  = these are capacity providers 

-- go to democluster --> infrastructure 

        - we can launch the ec2 instances directly in the cluster through an ASG 

-- if u change desired capacity is 1 , it will create 1 ec2 for u 

-- democluster --> infrastructure --> the created instance is show in Container instances , these instance can be create by FARGATE / FARGATE_SPOT / Our ASG 



---- create an ECS service 

-- u need to create task definition, create new task definition

-- create TD with the name "nginxdemos-hello"

     - nginxdemos-hello : this is from the official dockerhub page from internet ,we are using this in this demo

-- Infrastructure requirements = AWS Fargate 

     - u can also do select ec2 , but here i want to be serverless

-- OS, Architecture, Network mode = Linux/x86_64

-- Task size = CPU = .5 vcpu and memory = 1 GB

-- IN Container – 1 

     - Name = nginxdemos-hello   and Image URI = nginxdemos/hello : this will directly pull image from the dockerhub repo

-- keep remaining are default

-- create TD with this configuration , 

-- let's launch this task definition as a service.

-- democluster --> create service 

-- Compute options = Launch type 

-- Launch type = Fargate

-- Application type = Service : Launch a group of tasks handling a long-running computing work that can be stopped and restarted. For example, a web application

             - Task : Launch a standalone task that runs and terminates. For example, a batch job.

-- for this demo choose service

-- choose family and revision

-- Service name = same as family name

-- create one new sg in Network field , allow HTTP from anywhere and public ip turned On

-- and also create NEW ALB for this demo in load balcer section

-- create service , wait for few minutes to create 

-- once the service is get created do observe the service 

-- the service is linked to the target group and this target group is present infront of LB , 

-- in the target , u can see ip address , this is ip of ur container 

-- now go to load balancer and copy the DNS , paste in browser , u will get nginx welcome page  , /hello with dns in browser , ---> get o/p as /hello 

-- now here we have one service , u can also launch some more 

-- cluster --> service --> democluster --> update service

-- put desired = 3 1 per AZ , now we have two more tasks being provisioned and they are provisioned on the Fargate engine.

-- So that means that behind the scenes, AWS is going to provision automatically the resource that it needs to launch these tasks.

-- now do refresh in the browser , it will refresh for 3 services , ALB is distributing the load equally

-- to avoid charges , make sure our desired capacity = 0 in services and ASG both 






-------------------------------------------------- ECS Service Auto Scaling


• Automatically increase/decrease the desired number of ECS tasks

• Amazon ECS Auto Scaling uses "AWS Application Auto Scaling" , we have three metrics we can scale on using the service.

    • ECS Service Average CPU Utilization
    • ECS Service Average Memory Utilization-Scale on RAM
    • ALB Request Count Per Target–metric coming from the ALB


• Target Tracking – scale based on target value for a specific CloudWatch metric

• Step Scaling – scale based on a specified CloudWatch Alarm

• Scheduled Scaling – scale based on a specified date/time (predictable changes)

• ECS Service Auto Scaling (task level) ≠ EC2 Auto Scaling (EC2 instance level)

    - IMP NOTE : Remember, that scaling your service, your ECS Service, at the task level is not equal to scaling your cluster of EC2 instances if you are in the EC2 launch type.

• Fargate Auto Scaling is much easier to setup (because Serverless)



------------------------------------------------ EC2 Launch Type – Auto Scaling EC2 Instances

• Accommodate ECS Service Scaling by adding underlying EC2 Instances

-- We have 2 types


1 • Auto Scaling Group Scaling

    • Scale your ASG based on CPU Utilization 
    • Add EC2 instances over time


2 • ECS Cluster Capacity Provider
 
     • Used to automatically provision and scale the infrastructure for your ECSTasks
     • Capacity Provider paired with an Auto Scaling Group
     • Add EC2 Instances when you’re missing capacity (CPU, RAM...)



IMP NOTE : So if you have to choose between Auto Scaling Group Scaling and ECS Cluster Capacity Provider, please use ECS Cluster Capacity Provider for your EC2 launch type.


USer -------------> CloudWatch Metric (ECS Service CPU Usage) ---------------(Trigger)-------------->CloudWatch Alarm -----------(scale)-------> ASG / Capacity providers





------------------------------------------------ ECS Rolling Updates


• When updating from v1 to v2, we can control how many tasks can be started and stopped, and in which order

-- you will have two settings, the minimum healthy percent and the maximum percent.

-- So by default they're 100 and 200

-- EG : So your ECS service, for example, this one is running nine tasks represents an actual running capacity of 100%. 
    
         - And then if you set a minimum healthy percent of less than 100, this is going to say, "Hey you're allowed to terminate all the tasks on the right hand side, as long as we have enough tasks to have a percentage over the minimum healthy percent."

         - And in the maximum percent shows you how many new tasks you can create of the version two, to basically roll updates your service.

         - So this is how these two settings would impact your updates. 

         - so you will go ahead, create new tasks, then terminate all tasks and so on. All to make sure that all your tasks are going to be terminated and then updated to a newer version.


-- lets discuss 2 scenarios


------------------------------------------- 1 ECS Rolling Update – Min 50%, Max 100% 


 • Starting number of tasks: 4

   - In this case, we're going to lose four tasks to be terminated , so that we're running at 50% capacity.

   - Then two new tasks are going to be created, Now we're back at 100% capacity.

   - Then two old tasks are going to be terminated, we're back at 50% capacity.And two new tasks are going to be created, we're back at 100 capacity.

   - we have done a rolling updates.

   - In this case, we have been terminating tasks because we set the minimum to 50% and the maximum to 100%.



------------------------------------------- 2 ECS Rolling Update – Min 100%, Max 150%


• Starting number of tasks: 4

   - We cannot terminate a task because the minimum is 100%.

   - Therefore we can go into create two new tasks and this will bring our capacity to 150%. (total 6)

   - Then because we are above the minimum 100% we can terminate two old task and we're back at 100%.

   - Then we will create two new tasks and finally, terminates two old tasks. And this will have performed our rolling updates for our ECS service.




----------------------------------------- Amazon ECS – Task Definitions

• Task definitions are metadata in JSON form to tell ECS how to run a Docker container

• It contains crucial information, such as:
    
    • Image Name
    • Port Binding for Container and Host • Memory and CPU required
    • Environment variables
    • Networking information
    • IAM Role
    • Logging configuration (ex CloudWatch)

• Can define up to 10 containers in a Task Definition


-- Amazon ECS allows you to run and maintain a specified number of instances of a task definition simultaneously in an Amazon ECS cluster. This is called a service.



-------------------------------------- Amazon ECS – Load Balancing (EC2 Launch Type)


• We get a Dynamic Host Port Mapping if you define only the container port in the task definition

    - So if you have load balancing and you're using the EC2 launch type, then you're going to get what's called a Dynamic Host Port Mapping. If you define only the container port and the task definition.

Explanation : 

    - So we are running for example, an ECS task, and all of them have the container port set to 80 but the host port set to zero,meaning not set.

    - the host port is going to be random, is going to be dynamic.

    - so, each ECS task from within the EC2 instance, is going to be accessible from a different port on the host,the EC2 instance.

    - therefore, if you define an application load balancer , then you may say, well, it is difficult for the ALB to connect to the ECS test because the port is changing.

    - But the ALB when linked to an ECS service knows how to find the right port, thanks to the Dynamic Host Port Mapping feature.

NOTE : but it does not work with a classic load balancer because it is older generation.


• You must allow on the EC2 instance’s Security Group any port from the ALB’s Security Group







-------------------------------------- Amazon ECS – Load Balancing (Fargate)


• Each task has a unique private IP

• Only define the container port (host port is not applicable)

   -  because this is Fargate, there is no host


-- for example, with four tasks each task is going to get its own private IP through an Elastic Network Interface or ENI. And then each ENI is going to get the same container ports.

-- And therefore, when you have an ALB, then to connect to the Fargate task, it's just going to connect to all all of them on the same port on port 80.



• Example

   • ECS ENI Security Group

         • Allow port 80 from the ALB


   • ALB Security Group

         • Allow port 80/443 from web





------------------------------------------------------ Amazon ECS One IAM Role per Task Definition


-- you should know that IAM roles are assigned per task definition.

-- you have a task definition and then you assign an ECS task role. And this will allow you, for example, for your ECS tasks out of your task definition, to access the Amazon S3 service.

-- And therefore when you create an ECS service from this task definition then each ECS task automatically is going to assume and inherit this ECS task role.

NOTE :  you should know that the role is defined at the task definition level, not at this service level.so, therefore all the tasks within your service, are going to get access to Amazon S3.





----------------------------------------------------- Amazon ECS – Environment Variables


• Environment Variable

    • Hardcoded – e.g., URLs
    • SSM Parameter Store – sensitive variables (e.g., API keys, shared configs)
    • Secrets Manager – sensitive variables (e.g., DB passwords)


• Environment Files (bulk) – Amazon S3



---------------------------------------------------- Amazon ECS – Data Volumes (Bind Mounts)


Bind Mount :

-- With bind mounts, a file or directory on a host, such as an Amazon EC2 instance, is mounted into a container. Bind mounts are supported for tasks that are hosted on both Fargate and Amazon EC2 instances.

-- Bind mounts are tied to the lifecycle of the container that uses them. After all of the containers that use a bind mount are stopped, such as when a task is stopped, the data is removed.

-- For tasks that are hosted on Amazon EC2 instances, the data can be tied to the lifecycle of the host Amazon EC2 instance by specifying a host and optional sourcePath value in your task definition. 

The following are common use cases for bind mounts.

  - To provide an empty data volume to mount in one or more containers.
  
  - To mount a host data volume in one or more containers.
  
  - To share a data volume from a source container with other containers in the same task.

  - To expose a path and its contents from a Dockerfile to one or more containers.




• Share data between multiple containers in the same Task Definition

• Works for both EC2 and Fargate tasks

• EC2 Tasks – using EC2 instance storage

     • Data are tied to the lifecycle of the EC2 instance

• Fargate Tasks – using ephemeral storage
  
     • Data are tied to the container(s) using them
     • 20 GiB – 200 GiB (default 20 GiB)


• Use cases:

   • Share ephemeral data between multiple containers

   • “Sidecar”container pattern, where the “sidecar” container used to send metrics/logs to other destinations (separation of conerns)







----------------------------------------------------  Amazon ECS – Task Placement


• When an ECS task is started with EC2 Launch Type, ECS must determine where to place it, with the constraints of CPU and memory (RAM) and available port

• Similarly, when a service scales in, ECS needs to determine which task to terminate

• You can define:
  
    • Task Placement Strategy
    • Task Placement Constraints


• Note: only for ECS Tasks with EC2 LaunchType (Fargate not supported)



----------------------------------------------------  Amazon ECS – Task Placement Process


• Task Placement Strategies are a best effort


• When Amazon ECS places a task, it uses the following process to select the appropriate EC2 Container instance:

   1. Identify which instances that satisfy the CPU, memory, and port requirements

   2. Identify which instances that satisfy the Task Placement Constraints

   3. Identify which instances that satisfy the Task Placement Strategies

   4. Select the instances for task placement




---------------------------------------------------- Amazon ECS –Task Placement Strategies


• Binpack

    • Tasks are placed on the least available amount of CPU and Memory

    • Minimizes the number of EC2 instances in use (cost savings)


JSON :


"placementStrategy": [
    {
        "field": "memory",
        "type": "binpack"
    }
]



• Random

    • Tasks are placed randomly


JSON : 



"placementStrategy": [
    {
       
        "type": "random"
    }
]



• Spread


  • Tasks are placed evenly based on the specified value

  • Example: instanceId, attribute:ecs.availability-zone, ...


  JSON :

  "placementStrategy": [
    {
       
        "type": "spread",
        "field": "attribute:ecs.availability-zone"
    }
]



-------------------- You can mix them together


1 we can have a spread on availability zone and then a spread on instance ID

   
EG :

 "placementStrategy": [
    {

         "field": "attribute:ecs.availability-zone"
         "type": "spread",
       
    },

    {
          "field": "instanceid"
         "type": "spread",
    }
]




2  we can have a spread on availability zone and then a binpack on memory.

    
EG :

"placementStrategy": [
    {

         "field": "attribute:ecs.availability-zone"
         "type": "spread",
       
    },

    {
          "field": "memory"
         "type": "binpack",
    }
]






---------------------------------------------------- Amazon ECS –Task Placement Constraints


1  distinctInstance

     • Tasks are placed on a different EC2 instance

     - So you will never have two tasks on the same instance.

    
 "placementStrategy": [
    {
       
        "type": " distinctInstance"
        
    }
]


2   memberOf

    • Tasks are placed on EC2 instances that satisfy a specified expression

    • Uses the Cluster Query Language (advanced)

EG: 1 

    "placementStrategy": [
    {
       
        "type": "memberOf"
        "expression": "attribute:ecs.availability-zone in [ap-south-1,ap-south-2]"
        
    }
]

EG : 2 


"placementStrategy": [
    {
       
        "type": "memberOf"
        "expression": "attribute:ecs.instance-type =~ t2.*"
        
    }
]






---------------------------------------------------- Amazon ECR

• ECR = Elastic Container Registry

• Store and manage Docker images on AWS

• Private and Public repository (Amazon ECR Public Gallery https://gallery.ecr.aws)

• Fully integrated with ECS, backed by Amazon S3

• Access is controlled through IAM (permission errors => policy)

• Supports image vulnerability scanning, versioning, image tags, image lifecycle, ...




----------------------------------------------------  Amazon ECR – Using AWS CLI

• Login Command

   • AWS CLI v2

        aws ecr get-login-password --region region | docker login --username AWS --password-stdin aws_account_id.dkr.ecr.region.amazonaws.com



• Docker Commands
 
   • Push

       docker push aws_account_id.dkr.ecr.region.amazonaws.com/demo:latest


   • Pull
     
       docker pull aws_account_id.dkr.ecr.region.amazonaws.com/demo:latest



• In case an EC2 instance (or you) can’t pull a Docker image, check IAM permissions





---------------------------------------------------- AWS Copilot


• CLI tool to build, release, and operate production-ready containerized apps
      
      - So Copilot is not a service,


• The idea is that we want to remove the difficulty of running apps on AppRunner, ECS and Fargate, by just using a CLI tool to deploy to these environments.

• Helps you focus on building apps rather than setting up infrastructure

• Provisions all required infrastructure for containerized apps (ECS,VPC, ELB, ECR...) is done for you by Copilot.

• Automated deployments with one command using CodePipeline

• Deploy to multiple environments

• Troubleshooting, logs, health status...



Microservices Architecture
Use CLI or YAML to describe the architecture of your applications   --------------------------------> AWS Copilot CLI for containerized applications (Well-architected infrastructure setup, Deployment Pipeline, Effective Operations and Troubleshooting)----------------> Amazon ECS / AWS Fargate / AWS App Runner



------------------------------------- LAB for Copilot

-- open cloud9 , create environment

-- all are default , create environment

sudo curl -Lo /usr/local/bin/copilot https://github.com/aws/copilot-cli/releases/latest/download/copilot-linux \
   && sudo chmod +x /usr/local/bin/copilot \
   && copilot --help


-- by using the above command we can install the copilot in the Identify

-- make sure that docker should be installed in the IDE , check by typing docker

-- clone the url from the github
  
      git clone https://github.com/aws-samples/aws-copilot-sample-service example

-- do cd example

-- this example folder contains docker file , and index.html files 

-- do copilot init

-- So this is the Copilot CLI and it's going to give us some questions. And with it we're going to be able to set up a containerized application on AWS.

-- Application name: copilot-guide

 Which workload type best represents your architecture?  [Use arrows to move, type to filter, ? for more help]
  > Request-Driven Web Service  (App Runner)
    Load Balanced Web Service   (Public. ALB by default. Internet to ECS on Fargate)
    Backend Service             (Private. ALB optional. ECS on Fargate)
    Worker Service              (Events to SQS to ECS on Fargate)
    Static Site                 (Internet to CDN to S3 bucket)
    Scheduled Job               (Scheduled event to State Machine to Fargate)


-- u will get this once u give ur application load balancer 

-- here we have LB service web app

-- Service name: web-app
 
   Which Dockerfile would you like to use for web-app?  [Use arrows to move, type to filter, ? for more help]
  > ./Dockerfile
    Enter custom path for your Dockerfile
    Use an existing image instead

-- choose 1st option

-- select N 

-- in web-app folder one manifest file will get created here 

-- now create an environment to run our application in.

    copilot env init --name prod --profile default --app copilot-guide\

-- choose default 

-- now now it's going to update all the resources 

-- now go to cloudformation and check StackSet-copilot-guide-infrastructure --> resource , it will create ecr repo , s3 bucket and bucket policy and KMS created for us

-- next what we have to do is to actually go ahead and provision our application.

-- once u run copilot env deploy --name prod  

-- it will gives u InvalidClientTokenId error , so to avoid this , u can do  click on cloud9 logo --> preferences --> aws settings --> disable temporary credentials 

-- now go to IAM --> create user --> with administration access policy --> generate Access key 

-- now do aws configure and give details and o/p format is JSON

-- now it is working , see what it is created for u 

-- check in ecs cluster got vreated but no services are there 

-- so now run copilot deploy

-- so it will search for our appn "web-app" and choose environment to run our application

-- So now it goes ahead and uses Docker to actually build our final Docker image.

-- Then it pushes that Docker image into ECR, and then from ECR is going to create an ECS service that will be referencing that image, and will be started on our ECS cluster.

-- now wait for 5-7 minutes , it will get created the whole process for u  do not close the window unitl it get created 

- Creating the infrastructure for stack copilot-guide-prod-web-app                [create complete]  [351.8s]
  - Service discovery for your services to communicate within the VPC             [create complete]  [0.0s]
  - Update your environment's shared resources                                    [update complete]  [172.8s]
    - A security group for your load balancer allowing HTTP traffic               [create complete]  [3.6s]
    - An Application Load Balancer to distribute public traffic to your services  [create complete]  [151.8s]
    - A load balancer listener to route HTTP traffic                              [create complete]  [1.1s]
  - An IAM role to update your environment stack                                  [create complete]  [16.3s]
  - An IAM Role for the Fargate agent to make AWS API calls on your behalf        [create complete]  [16.3s]
  - An HTTP listener rule for path `/` that forwards HTTP traffic to your tasks   [create complete]  [0.0s]
  - A custom resource assigning priority for HTTP listener rules                  [create complete]  [3.0s]
  - A CloudWatch log group to hold your service logs                              [create complete]  [7.3s]
  - An IAM Role to describe load balancer rules for assigning a priority          [create complete]  [16.3s]
  - An ECS service to run and maintain your tasks in the environment cluster      [create complete]  [122.5s]
    Deployments                                                                                      
               Revision  Rollout      Desired  Running  Failed  Pending                                       
      PRIMARY  1         [completed]  1        1        0       0                                             
  - A target group to connect the load balancer to your service on port 80        [create complete]  [15.3s]
  - An ECS task definition to group your containers and run them on ECS           [create complete]  [0.0s]
  - An IAM role to control permissions for the containers in your tasks


-- these are things that it will create all the complexity of thinking about what you need to actually create when you run an application on ECS is taken away by Copilot.

-- now do check in ecs , the service is get created 

-- now copy the link and paste in the broswer , u will get o/p

-- all the complexity will tAKEN BY Copilot for u
    
-- now delete resource , do run copilot app delete

-- wait for some time it will get deleted 

-- delete user in iam also 


---------------------------------------------------- Amazon EKS(Elastic Kubernetes service) Overview

• Amazon EKS = Amazon Elastic Kubernetes Service

• It is a way to launch managed Kubernetes clusters on AWS

• Kubernetes is an open-source system for automatic deployment, scaling and management of containerized (usually Docker) application

• It’s an alternative to ECS, similar goal but different API

• EKS supports EC2 if you want to deploy worker nodes or Fargate to deploy serverless containers

• Use case: if your company is already using Kubernetes on-premises or in another cloud, and wants to migrate to AWS using Kubernetes

• Kubernetes is cloud-agnostic (can be used in any cloud – Azure, GCP...)

• For multiple regions, deploy one EKS cluster per region

• Collect logs and metrics using CloudWatch Container Insights



----------------------- Amazon EKS – Node Types

• Managed Node Groups

    • Creates and manages Nodes (EC2 instances) for you
    • Nodes are part of an ASG managed by EKS
    • Supports On-Demand or Spot Instances

• Self-Managed Nodes

    • Nodes created by you and registered to the EKS cluster and managed by an ASG
    • You can use prebuilt AMI - Amazon EKS Optimized AMI
    • Supports On-Demand or Spot Instances


• AWS Fargate

    • No maintenance required; no nodes managed


------------------ Amazon EKS – Data Volumes

• Need to specify StorageClass manifest on your EKS cluster

• Leverages a Container Storage Interface (CSI) compliant driver

• Support for...
   
   • Amazon EBS
   • Amazon EFS (works with Fargate) 
   • Amazon FSx for Lustre
   • Amazon FSx for NetApp ONTAP





================================================= AWS Elastic Beanstalk ===============================================


Developer problems on AWS

  • Managing infrastructure
  • Deploying Code
  • Configuring all the databases, load balancers, etc
  • Scaling concerns


• Most web apps have the same architecture (ALB + ASG)

• All the developers want is for their code to run!

• Possibly, consistently across different applications and environments



------------------------------------- Elastic Beanstalk – Overview

• Elastic Beanstalk is a developer centric view of deploying an application on AWS

• It uses all the component’s we’ve seen before: EC2, ASG, ELB, RDS, ...

• Managed service

     • Automatically handles capacity provisioning, load balancing, scaling, application health monitoring, instance configuration, ...

     • Just the application code is the responsibility of the developer

• We still have full control over the configuration

• Beanstalk is free but you pay for the underlying instances



------------------------------------- Elastic Beanstalk – Components

• Application: collection of Elastic Beanstalk components (environments, versions, configurations, ...)

• Application Version: an iteration of your application code (v1, v2 , v3)

• Environment 

      • Collection of AWS resources running an application version (only one application version at a time in an environment),  where we can see we can actually update an application version within an environment from version one to version two.
   
      • Tiers: Web Server Environment Tier & Worker Environment Tier

      • You can create multiple environments (dev, test, prod, ...)



------------------------------------- Elastic Beanstalk – Supported Platforms

• Go
• Java SE
• Java withTomcat
• .NET Core on Linux
• .NET on Windows Server 
• Node.js
• PHP
• Python
• Ruby
• Packer Builder
• Single Container Docker 
• Multi-container Docker 
• Preconfigured Docker


------------------------------------- Web ServerTier vs. WorkerTier (environments)


 Web ServerTier :

 -- This is the traditional architecture that we know, where we have a load balancer and then it's sending traffic to an auto scaling group that has multiple EC2 instances that are going to be your web server.


 WorkerTier :

 -- So this time there is no clients accessing directly your EC2 instances. We're going to use an SQS queue, which is a message queue and the message will be sent into the SQS queue and the EC2 instances are going to be workers,

 -- because they're going to pull messages from the SQS queue to process them.

 • Scale based on the number of SQS messages

 • Can push messages to SQS queue from anotherWeb ServerTier




------------------------------------ Elastic Beanstalk Deployment Modes

1 Single Instance Great for dev

  -- In this case, you'll have one EC2 instance which will have an Elastic IP, potentially it can also launch an RDS database and so on,

  -- but it's all based on one instance with an Elastic IP. It's great for development purposes,


NOTE : but then if you wanted to scale a real Elastic Beanstalk mode, then you would go for high available with a load balancer,


2  High Availability with Load Balancer Great for prod

   -- which is great for production environments, in which case, you can have a load balancer distributing the loads across multiple EC2 instances that are managed for an auto scaling group and multiple available zones.

   -- And finally, you may have an RDS database that's also multi AZ with a master and a standby.


